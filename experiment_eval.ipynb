{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nurro\\.conda\\envs\\tf_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from utils.rag import *\n",
    "\n",
    "llm = Ollama(model=\"gemma:2b\", request_timeout=60.0)\n",
    "collection=Ingestion(path='data/SPOTIFY_REVIEWS.csv',embedding_model=\"BAAI/bge-small-en-v1.5\",rowlimit=2000)\n",
    "collection.run()\n",
    "bot=RAGBot(collection=collection,MODEL_NAME=\"gemma:2b\",REQUEST_TIMEOUT=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference process\n",
      "inference process\n",
      "inference process\n",
      "inference process\n"
     ]
    }
   ],
   "source": [
    "questions=[\n",
    "    \"What are the specific features or aspects that users appreciate the most in our application?\",\n",
    "    \"In comparison to our application, which music streaming platform are users most likely to compare ours with?\",\n",
    "    \"What are the primary reasons users express dissatisfaction with Spotify?\",\n",
    "    \"Can you identify emerging trends or patterns in recent user reviews that may impact our product strategy?\",\n",
    "    ]\n",
    "queries=[]\n",
    "answers=[]\n",
    "for que in questions:\n",
    "    que,answ=bot.qna(question=que,RAG_KEYWORD=60,get_query=True)\n",
    "    queries.append(que)\n",
    "    answers.append(answ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(questions)):\n",
    "    with open(f'data/eval/answer_rel_{i}.txt', 'w') as file:\n",
    "        a0=f'''\n",
    "Your task is to evaluate if the response is relevant to the query.\n",
    "The evaluation should be performed in a step-by-step manner by answering the following questions:\n",
    "1. Does the provided response match the subject matter of the user's query?\n",
    "2. Does the provided response attempt to address the focus or perspective\n",
    "on the subject matter taken on by the user's query?\n",
    "Each question above is worth 1 point. Provide detailed feedback on response according to the criteria questions above\n",
    "After your feedback provide a final result by strictly following this format: '[RESULT] followed by the integer number representing the total score assigned to the response'\n",
    "Query: {queries[i]}\n",
    "Response: {answers[i]}\n",
    "Feedback:\n",
    "'''\n",
    "        # Write the text to the file\n",
    "        file.write(a0)\n",
    "\n",
    "    with open(f'data/eval/context_rel_{i}.txt', 'w') as file:\n",
    "        a1=f'''\n",
    "Your task is to evaluate if the retrieved context from the document sources are relevant to the query\n",
    "The evaluation should be performed in a step-by-step manner by answering the following questions:\n",
    "1. Does the retrieved context match the subject matter of the user's query?\n",
    "2. Can the retrieved context be used exclusively to provide a full answer to the user's query?\n",
    "Each question above is worth 2 points, where partial marks are allowed and encouraged. Provide detailed feedback on the response\n",
    "according to the criteria questions previously mentioned.\n",
    "After your feedback provide a final result by strictly following this format: \n",
    "[RESULT] followed by the float number representing the total score assigned to the response\n",
    "Query: {questions[i]}\n",
    "Context: {queries[i]}\n",
    "Feedback:\n",
    "'''\n",
    "        # Write the text to the file\n",
    "        file.write(a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
